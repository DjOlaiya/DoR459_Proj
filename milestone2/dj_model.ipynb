{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Milestone 2\n",
    "## 2.1 and 2.2 Split Train Dataset, Build and Evaluate a Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as c\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm #creates progress bar to let you know how long is left till function is complete\n",
    "import xgboost as xgb\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../dataset/cases_train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 367634 entries, 0 to 367633\nData columns (total 23 columns):\n #   Column                  Non-Null Count   Dtype  \n---  ------                  --------------   -----  \n 0   Unnamed: 0              367634 non-null  int64  \n 1   index                   367634 non-null  int64  \n 2   age                     367634 non-null  int64  \n 3   sex                     367634 non-null  object \n 4   province                367634 non-null  object \n 5   country                 367634 non-null  object \n 6   date_confirmation       367634 non-null  object \n 7   additional_information  367634 non-null  object \n 8   source                  367634 non-null  object \n 9   outcome                 367634 non-null  object \n 10  Province_State          334812 non-null  object \n 11  Country_Region          356275 non-null  object \n 12  Last_Update             356275 non-null  object \n 13  Lat_right               356275 non-null  float64\n 14  Long_right              356275 non-null  float64\n 15  Confirmed               356275 non-null  float64\n 16  Deaths                  356275 non-null  float64\n 17  Recovered               356275 non-null  float64\n 18  Active                  356275 non-null  float64\n 19  Combined_Key            356275 non-null  object \n 20  Incidence_Rate          356275 non-null  float64\n 21  Case-Fatality_Ratio     356275 non-null  float64\n 22  dist_between_in_km      367634 non-null  float64\ndtypes: float64(9), int64(3), object(11)\nmemory usage: 64.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# this way I dont have to load data all the time\n",
    "df = raw_data.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 162 ms, sys: 14.3 ms, total: 177 ms\nWall time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#remove nan values\n",
    "df = df.drop(['Unnamed: 0','index','source','additional_information','Last_Update','Lat_right','Long_right','Province_State','Country_Region'],1)\n",
    "df['Confirmed'].fillna(df['Confirmed'].mean(),inplace=True)\n",
    "df['Deaths'].fillna(df.Deaths.mean(),inplace=True)\n",
    "df['Recovered'].fillna(df.Recovered.mean(),inplace=True)\n",
    "df['Active'].fillna(df.Active.mean(),inplace=True)\n",
    "df['Incidence_Rate'].fillna(df.Incidence_Rate.mean(),inplace=True)\n",
    "df['Case-Fatality_Ratio'].fillna(df['Case-Fatality_Ratio'].mean(),inplace=True)\n",
    "df.date_confirmation = pd.to_datetime(df.date_confirmation,infer_datetime_format=True) \n",
    "df.Combined_Key.fillna((df.province+\" ,\"+df.country),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this as a string so that my encode function doesn't pick it up\n",
    "df.outcome = df.outcome.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might create duplicates so check and delete them\n",
    "def dropDuplicates(data):\n",
    "    duplicates = data.columns[data.columns.duplicated()]\n",
    "    if len(duplicates) > 0:\n",
    "        data = data.loc[:,~data.columns.duplicated()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once hot encode and add new cols to dataframe\n",
    "def oneHotEncode_df(dataframe):\n",
    "    col2Encode = list(dataframe.select_dtypes(include=['object'])) #gets a list of all the features that are objects assumption is that those are categorical\n",
    "    dummies = pd.get_dummies(dataframe,columns=col2Encode,prefix=col2Encode,sparse=True)\n",
    "    res = pd.concat([dataframe, dummies], axis=1)\n",
    "    #if we decide to drop one hot encoded values\n",
    "    res = res.drop(col2Encode, axis=1)\n",
    "    output = dropDuplicates(res)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.17 s, sys: 0 ns, total: 1.17 s\nWall time: 1.27 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age date_confirmation          outcome      Confirmed       Deaths  \\\n",
       "0         7        2020-05-26        recovered  238828.000000  4907.000000   \n",
       "1         7        2020-05-20     hospitalized  342788.000000  4869.000000   \n",
       "2         7        2020-05-26     hospitalized    2859.000000     2.000000   \n",
       "3         3        2020-03-15  nonhospitalized   46779.000000  1871.000000   \n",
       "4         7        2020-05-20     hospitalized  120336.000000  3286.000000   \n",
       "...     ...               ...              ...            ...          ...   \n",
       "367629    3        2020-03-31  nonhospitalized  106331.902334  2739.064287   \n",
       "367630    7        2020-04-16     hospitalized  238828.000000  4907.000000   \n",
       "367631    7        2020-05-30     hospitalized    2859.000000     2.000000   \n",
       "367632    3        2020-03-02        recovered   57558.000000    27.000000   \n",
       "367633    1        2020-05-27  nonhospitalized   33299.000000  1911.000000   \n",
       "\n",
       "            Recovered        Active  Incidence_Rate  Case-Fatality_Ratio  \\\n",
       "0       201671.000000  32250.000000     1276.409575             2.054617   \n",
       "1       270094.000000  67825.000000      144.099577             1.420411   \n",
       "2         2639.000000    218.000000      464.331421             0.069955   \n",
       "3        41228.000000   3680.000000      422.592353             3.999658   \n",
       "4       100974.000000  16076.000000      188.400627             2.730687   \n",
       "...               ...           ...             ...                  ...   \n",
       "367629   77838.956438  25753.923921      968.698456             2.721038   \n",
       "367630  201671.000000  32250.000000     1276.409575             2.054617   \n",
       "367631    2639.000000    218.000000      464.331421             0.069955   \n",
       "367632   57142.000000    389.000000      983.839751             0.046909   \n",
       "367633       0.000000  31388.000000     1625.927734             5.738911   \n",
       "\n",
       "        dist_between_in_km  ...  Combined_Key_Zamboanga del Sur ,Philippines  \\\n",
       "0                10.390897  ...                                            0   \n",
       "1               209.514800  ...                                            0   \n",
       "2               204.687238  ...                                            0   \n",
       "3               126.061115  ...                                            0   \n",
       "4               217.585376  ...                                            0   \n",
       "...                    ...  ...                                          ...   \n",
       "367629           -1.000000  ...                                            0   \n",
       "367630           10.390897  ...                                            0   \n",
       "367631          111.254821  ...                                            0   \n",
       "367632            0.367129  ...                                            0   \n",
       "367633           47.256340  ...                                            0   \n",
       "\n",
       "        Combined_Key_Zamfara ,Nigeria  Combined_Key_Zanjan ,Iran  \\\n",
       "0                                   0                          0   \n",
       "1                                   0                          0   \n",
       "2                                   0                          0   \n",
       "3                                   0                          0   \n",
       "4                                   0                          0   \n",
       "...                               ...                        ...   \n",
       "367629                              0                          0   \n",
       "367630                              0                          0   \n",
       "367631                              0                          0   \n",
       "367632                              0                          0   \n",
       "367633                              0                          0   \n",
       "\n",
       "        Combined_Key_Zeeland, Netherlands  Combined_Key_Zhejiang, China  \\\n",
       "0                                       0                             0   \n",
       "1                                       0                             0   \n",
       "2                                       0                             0   \n",
       "3                                       0                             0   \n",
       "4                                       0                             0   \n",
       "...                                   ...                           ...   \n",
       "367629                                  0                             0   \n",
       "367630                                  0                             0   \n",
       "367631                                  0                             0   \n",
       "367632                                  0                             0   \n",
       "367633                                  0                             0   \n",
       "\n",
       "        Combined_Key_Zimbabwe  Combined_Key_Zuid-Holland, Netherlands  \\\n",
       "0                           0                                       0   \n",
       "1                           0                                       0   \n",
       "2                           0                                       0   \n",
       "3                           0                                       0   \n",
       "4                           0                                       0   \n",
       "...                       ...                                     ...   \n",
       "367629                      0                                       0   \n",
       "367630                      0                                       0   \n",
       "367631                      0                                       0   \n",
       "367632                      0                                       0   \n",
       "367633                      0                                       0   \n",
       "\n",
       "        Combined_Key_galapagos ,Ecuador  Combined_Key_Ñeembucu ,Paraguay  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "...                                 ...                              ...   \n",
       "367629                                0                                0   \n",
       "367630                                0                                0   \n",
       "367631                                0                                0   \n",
       "367632                                0                                0   \n",
       "367633                                0                                0   \n",
       "\n",
       "        Combined_Key_ñeembucu ,Paraguay  \n",
       "0                                     0  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  \n",
       "...                                 ...  \n",
       "367629                                0  \n",
       "367630                                0  \n",
       "367631                                0  \n",
       "367632                                0  \n",
       "367633                                0  \n",
       "\n",
       "[367634 rows x 2789 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>date_confirmation</th>\n      <th>outcome</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Active</th>\n      <th>Incidence_Rate</th>\n      <th>Case-Fatality_Ratio</th>\n      <th>dist_between_in_km</th>\n      <th>...</th>\n      <th>Combined_Key_Zamboanga del Sur ,Philippines</th>\n      <th>Combined_Key_Zamfara ,Nigeria</th>\n      <th>Combined_Key_Zanjan ,Iran</th>\n      <th>Combined_Key_Zeeland, Netherlands</th>\n      <th>Combined_Key_Zhejiang, China</th>\n      <th>Combined_Key_Zimbabwe</th>\n      <th>Combined_Key_Zuid-Holland, Netherlands</th>\n      <th>Combined_Key_galapagos ,Ecuador</th>\n      <th>Combined_Key_Ñeembucu ,Paraguay</th>\n      <th>Combined_Key_ñeembucu ,Paraguay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2020-05-26</td>\n      <td>recovered</td>\n      <td>238828.000000</td>\n      <td>4907.000000</td>\n      <td>201671.000000</td>\n      <td>32250.000000</td>\n      <td>1276.409575</td>\n      <td>2.054617</td>\n      <td>10.390897</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>2020-05-20</td>\n      <td>hospitalized</td>\n      <td>342788.000000</td>\n      <td>4869.000000</td>\n      <td>270094.000000</td>\n      <td>67825.000000</td>\n      <td>144.099577</td>\n      <td>1.420411</td>\n      <td>209.514800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>2020-05-26</td>\n      <td>hospitalized</td>\n      <td>2859.000000</td>\n      <td>2.000000</td>\n      <td>2639.000000</td>\n      <td>218.000000</td>\n      <td>464.331421</td>\n      <td>0.069955</td>\n      <td>204.687238</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-03-15</td>\n      <td>nonhospitalized</td>\n      <td>46779.000000</td>\n      <td>1871.000000</td>\n      <td>41228.000000</td>\n      <td>3680.000000</td>\n      <td>422.592353</td>\n      <td>3.999658</td>\n      <td>126.061115</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>2020-05-20</td>\n      <td>hospitalized</td>\n      <td>120336.000000</td>\n      <td>3286.000000</td>\n      <td>100974.000000</td>\n      <td>16076.000000</td>\n      <td>188.400627</td>\n      <td>2.730687</td>\n      <td>217.585376</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>367629</th>\n      <td>3</td>\n      <td>2020-03-31</td>\n      <td>nonhospitalized</td>\n      <td>106331.902334</td>\n      <td>2739.064287</td>\n      <td>77838.956438</td>\n      <td>25753.923921</td>\n      <td>968.698456</td>\n      <td>2.721038</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367630</th>\n      <td>7</td>\n      <td>2020-04-16</td>\n      <td>hospitalized</td>\n      <td>238828.000000</td>\n      <td>4907.000000</td>\n      <td>201671.000000</td>\n      <td>32250.000000</td>\n      <td>1276.409575</td>\n      <td>2.054617</td>\n      <td>10.390897</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367631</th>\n      <td>7</td>\n      <td>2020-05-30</td>\n      <td>hospitalized</td>\n      <td>2859.000000</td>\n      <td>2.000000</td>\n      <td>2639.000000</td>\n      <td>218.000000</td>\n      <td>464.331421</td>\n      <td>0.069955</td>\n      <td>111.254821</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367632</th>\n      <td>3</td>\n      <td>2020-03-02</td>\n      <td>recovered</td>\n      <td>57558.000000</td>\n      <td>27.000000</td>\n      <td>57142.000000</td>\n      <td>389.000000</td>\n      <td>983.839751</td>\n      <td>0.046909</td>\n      <td>0.367129</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367633</th>\n      <td>1</td>\n      <td>2020-05-27</td>\n      <td>nonhospitalized</td>\n      <td>33299.000000</td>\n      <td>1911.000000</td>\n      <td>0.000000</td>\n      <td>31388.000000</td>\n      <td>1625.927734</td>\n      <td>5.738911</td>\n      <td>47.256340</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>367634 rows × 2789 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "# add dummy variables  \n",
    "ohe_df = oneHotEncode_df(df)\n",
    "ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7, Timestamp('2020-05-26 00:00:00'), 'recovered', ..., 0, 0, 0],\n",
       "       [7, Timestamp('2020-05-20 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       [7, Timestamp('2020-05-26 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       ...,\n",
       "       [7, Timestamp('2020-05-30 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       [3, Timestamp('2020-03-02 00:00:00'), 'recovered', ..., 0, 0, 0],\n",
       "       [1, Timestamp('2020-05-27 00:00:00'), 'nonhospitalized', ..., 0,\n",
       "        0, 0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ohe_np = ohe_df.to_numpy()\n",
    "ohe_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into dependent and independent var\n",
    "x = ohe_df.copy().drop(columns=['outcome','date_confirmation','dist_between_in_km'])\n",
    "y = ohe_df.outcome.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 33.9 s, sys: 0 ns, total: 33.9 s\nWall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split train data\n",
    "trainData_x, validationData_x, trainData_y, validationData_y = train_test_split(x,y, train_size=0.8, random_state=1)"
   ]
  },
  {
   "source": [
    "# ----------------------------------Model Building-----------------------------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 diff classififers and append them to list\n",
    "classifiers = []\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "classifiers.append(xgb_model)\n",
    "\n",
    "nn_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "classifiers.append(nn_model)\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "classifiers.append(svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test models with full samples\n",
    "# for clas in tqdm(classifiers):\n",
    "#     clas.fit(trainData_x,trainData_y)\n",
    "#     predicted = clas.predict(validationData_x)\n",
    "#     accuracy = accuracy_score(validationData_y,predicted)\n",
    "#     print(\"Accuracy of %s is %s\"%(clas, accuracy))\n",
    "#     con_mat = confusion_matrix(validationData_y,predicted)\n",
    "#     print(\"Confusion Matrix of %s is %s\"%(clas, con_mat))\n",
    "#     pickle.dump( clas, open( \"{}{}.pkl\".format(clas,i), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "218247    2\n",
       "33854     0\n",
       "234440    3\n",
       "316468    3\n",
       "250495    2\n",
       "         ..\n",
       "117583    3\n",
       "73349     2\n",
       "312201    3\n",
       "267336    3\n",
       "128037    0\n",
       "Name: outcome, Length: 294107, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_trainInt = pd.Series(trainData_y).replace({'recovered' : 0, 'deceased' : 1, 'nonhospitalized' : 2, 'hospitalized' : 3})\n",
    "y_trainInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "247886    2\n",
       "364290    2\n",
       "237307    3\n",
       "22967     3\n",
       "29696     3\n",
       "         ..\n",
       "47882     3\n",
       "319748    2\n",
       "153914    2\n",
       "219937    2\n",
       "352073    2\n",
       "Name: outcome, Length: 73527, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_validInt = pd.Series(validationData_y).replace({'recovered' : 0, 'deceased' : 1, 'nonhospitalized' : 2, 'hospitalized' : 3})\n",
    "y_validInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert into Dmatrix\n",
    "data_matrix = xgb.DMatrix(data=trainData_x,label=y_trainInt)\n",
    "valid_matrix = xgb.DMatrix(data=validationData_x,label=y_validInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = xgb.DMatrix(data=trainData_x.iloc[0:1000],label=y_trainInt.iloc[0:1000])\n",
    "vm = xgb.DMatrix(data=validationData_x.iloc[0:1000],label=y_validInt.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "connect ECONNREFUSED 127.0.0.1:45361",
     "traceback": [
      "Error: connect ECONNREFUSED 127.0.0.1:45361",
      "at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1141:16)"
     ]
    }
   ],
   "source": [
    "n = [1,5,10,25,50]\n",
    "\n",
    "for i in tqdm(n):\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=i)\n",
    "    xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "    predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "    tscore = xgb_model.score(trainData_x,y_trainInt)\n",
    "    print(\"train score is {}\".format(tscore))\n",
    "    vscore = xgb_model.score(validationData_x,y_validInt)\n",
    "    print(\"val score is {}\".format(vscore))\n",
    "    accuracy = accuracy_score(y_validInt,predicted)\n",
    "    print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "    con_mat = confusion_matrix(validationData_y,predicted)\n",
    "    print(\"Confusion Matrix of xgbmodel is {}\".format(con_mat))\n",
    "    pickle.dump( xgb_model, open( \"xgboost{}.pkl\".format(i), \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[08:32:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score is 0.7799916356972122\n",
      "val score is 0.7778639139363771\n",
      "Accuracy of XGBClassifier is 0.7778639139363771\n",
      "CPU times: user 2min 45s, sys: 7.78 s, total: 2min 53s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = [1,5,10,25,50]\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=1)\n",
    "xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "tscore = xgb_model.score(trainData_x,trainData_y)\n",
    "print(\"train score is {}\".format(tscore))\n",
    "vscore = xgb_model.score(validationData_x,validationData_y)\n",
    "print(\"val score is {}\".format(vscore))\n",
    "accuracy = accuracy_score(validationData_y,predicted)\n",
    "print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "pickle.dump( xgb_model, open( \"xgboost_n1.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[08:33:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score is 0.7809096689300152\n",
      "val score is 0.7787343424864336\n",
      "Accuracy of XGBClassifier is 0.7787343424864336\n",
      "CPU times: user 9min 24s, sys: 8.86 s, total: 9min 32s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=5)\n",
    "xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "tscore = xgb_model.score(trainData_x,trainData_y)\n",
    "print(\"train score is {}\".format(tscore))\n",
    "vscore = xgb_model.score(validationData_x,validationData_y)\n",
    "print(\"val score is {}\".format(vscore))\n",
    "accuracy = accuracy_score(validationData_y,predicted)\n",
    "print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "pickle.dump( xgb_model, open( \"xgboost_n5.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[08:36:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score is 0.7813380844386567\n",
      "val score is 0.779196757653651\n",
      "Accuracy of XGBClassifier is 0.779196757653651\n",
      "CPU times: user 17min 34s, sys: 11.6 s, total: 17min 46s\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=10)\n",
    "xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "tscore = xgb_model.score(trainData_x,trainData_y)\n",
    "print(\"train score is {}\".format(tscore))\n",
    "vscore = xgb_model.score(validationData_x,validationData_y)\n",
    "print(\"val score is {}\".format(vscore))\n",
    "accuracy = accuracy_score(validationData_y,predicted)\n",
    "print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "pickle.dump( xgb_model, open( \"xgboost_n10.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=25)\n",
    "xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "tscore = xgb_model.score(trainData_x,trainData_y)\n",
    "print(\"train score is {}\".format(tscore))\n",
    "vscore = xgb_model.score(validationData_x,validationData_y)\n",
    "print(\"val score is {}\".format(vscore))\n",
    "accuracy = accuracy_score(validationData_y,predicted)\n",
    "print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "pickle.dump( xgb_model, open( \"xgboost_n25.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=50)\n",
    "xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "tscore = xgb_model.score(trainData_x,trainData_y)\n",
    "print(\"train score is {}\".format(tscore))\n",
    "vscore = xgb_model.score(validationData_x,validationData_y)\n",
    "print(\"val score is {}\".format(vscore))\n",
    "accuracy = accuracy_score(validationData_y,predicted)\n",
    "print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "pickle.dump( xgb_model, open( \"xgboost_n50.pkl\", \"wb\" ) )"
   ]
  },
  {
   "source": [
    "# Exploratory Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}