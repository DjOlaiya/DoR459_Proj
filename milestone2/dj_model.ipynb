{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Milestone 2\n",
    "## 2.1 and 2.2 Split Train Dataset, Build and Evaluate a Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as c\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm #creates progress bar to let you know how long is left till function is complete\n",
    "import xgboost as xgb\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../dataset/cases_train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "index                         0\n",
       "age                           0\n",
       "sex                           0\n",
       "province                      0\n",
       "country                       0\n",
       "date_confirmation             0\n",
       "additional_information        0\n",
       "source                        0\n",
       "outcome                       0\n",
       "Province_State            32822\n",
       "Country_Region            11359\n",
       "Last_Update               11359\n",
       "Lat_right                 11359\n",
       "Long_right                11359\n",
       "Confirmed                 11359\n",
       "Deaths                    11359\n",
       "Recovered                 11359\n",
       "Active                    11359\n",
       "Combined_Key              11359\n",
       "Incidence_Rate            11359\n",
       "Case-Fatality_Ratio       11359\n",
       "dist_between_in_km            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 367634 entries, 0 to 367633\nData columns (total 23 columns):\n #   Column                  Non-Null Count   Dtype  \n---  ------                  --------------   -----  \n 0   Unnamed: 0              367634 non-null  int64  \n 1   index                   367634 non-null  int64  \n 2   age                     367634 non-null  int64  \n 3   sex                     367634 non-null  object \n 4   province                367634 non-null  object \n 5   country                 367634 non-null  object \n 6   date_confirmation       367634 non-null  object \n 7   additional_information  367634 non-null  object \n 8   source                  367634 non-null  object \n 9   outcome                 367634 non-null  object \n 10  Province_State          334812 non-null  object \n 11  Country_Region          356275 non-null  object \n 12  Last_Update             356275 non-null  object \n 13  Lat_right               356275 non-null  float64\n 14  Long_right              356275 non-null  float64\n 15  Confirmed               356275 non-null  float64\n 16  Deaths                  356275 non-null  float64\n 17  Recovered               356275 non-null  float64\n 18  Active                  356275 non-null  float64\n 19  Combined_Key            356275 non-null  object \n 20  Incidence_Rate          356275 non-null  float64\n 21  Case-Fatality_Ratio     356275 non-null  float64\n 22  dist_between_in_km      367634 non-null  float64\ndtypes: float64(9), int64(3), object(11)\nmemory usage: 64.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# this way I dont have to load data all the time\n",
    "df = raw_data.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 147 ms, sys: 25.5 ms, total: 173 ms\nWall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#remove nan values\n",
    "df = df.drop(['Unnamed: 0','index','source','additional_information','Last_Update','Lat_right','Long_right','Province_State','Country_Region'],1)\n",
    "df['Confirmed'].fillna(df['Confirmed'].mean(),inplace=True)\n",
    "df['Deaths'].fillna(df.Deaths.mean(),inplace=True)\n",
    "df['Recovered'].fillna(df.Recovered.mean(),inplace=True)\n",
    "df['Active'].fillna(df.Active.mean(),inplace=True)\n",
    "df['Incidence_Rate'].fillna(df.Incidence_Rate.mean(),inplace=True)\n",
    "df['Case-Fatality_Ratio'].fillna(df['Case-Fatality_Ratio'].mean(),inplace=True)\n",
    "df.date_confirmation = pd.to_datetime(df.date_confirmation,infer_datetime_format=True) \n",
    "df.Combined_Key.fillna((df.province+\" ,\"+df.country),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this as a string so that my encode function doesn't pick it up\n",
    "df.outcome = df.outcome.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might create duplicates so check and delete them\n",
    "def dropDuplicates(data):\n",
    "    duplicates = data.columns[data.columns.duplicated()]\n",
    "    if len(duplicates) > 0:\n",
    "        data = data.loc[:,~data.columns.duplicated()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once hot encode and add new cols to dataframe\n",
    "def oneHotEncode_df(dataframe):\n",
    "    col2Encode = list(dataframe.select_dtypes(include=['object'])) #gets a list of all the features that are objects assumption is that those are categorical\n",
    "    dummies = pd.get_dummies(dataframe,columns=col2Encode,prefix=col2Encode,sparse=True)\n",
    "    res = pd.concat([dataframe, dummies], axis=1)\n",
    "    #if we decide to drop one hot encoded values\n",
    "    res = res.drop(col2Encode, axis=1)\n",
    "    output = dropDuplicates(res)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.09 s, sys: 60.9 ms, total: 1.15 s\nWall time: 1.21 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age date_confirmation          outcome      Confirmed       Deaths  \\\n",
       "0         7        2020-05-26        recovered  238828.000000  4907.000000   \n",
       "1         7        2020-05-20     hospitalized  342788.000000  4869.000000   \n",
       "2         7        2020-05-26     hospitalized    2859.000000     2.000000   \n",
       "3         3        2020-03-15  nonhospitalized   46779.000000  1871.000000   \n",
       "4         7        2020-05-20     hospitalized  120336.000000  3286.000000   \n",
       "...     ...               ...              ...            ...          ...   \n",
       "367629    3        2020-03-31  nonhospitalized  106331.902334  2739.064287   \n",
       "367630    7        2020-04-16     hospitalized  238828.000000  4907.000000   \n",
       "367631    7        2020-05-30     hospitalized    2859.000000     2.000000   \n",
       "367632    3        2020-03-02        recovered   57558.000000    27.000000   \n",
       "367633    1        2020-05-27  nonhospitalized   33299.000000  1911.000000   \n",
       "\n",
       "            Recovered        Active  Incidence_Rate  Case-Fatality_Ratio  \\\n",
       "0       201671.000000  32250.000000     1276.409575             2.054617   \n",
       "1       270094.000000  67825.000000      144.099577             1.420411   \n",
       "2         2639.000000    218.000000      464.331421             0.069955   \n",
       "3        41228.000000   3680.000000      422.592353             3.999658   \n",
       "4       100974.000000  16076.000000      188.400627             2.730687   \n",
       "...               ...           ...             ...                  ...   \n",
       "367629   77838.956438  25753.923921      968.698456             2.721038   \n",
       "367630  201671.000000  32250.000000     1276.409575             2.054617   \n",
       "367631    2639.000000    218.000000      464.331421             0.069955   \n",
       "367632   57142.000000    389.000000      983.839751             0.046909   \n",
       "367633       0.000000  31388.000000     1625.927734             5.738911   \n",
       "\n",
       "        dist_between_in_km  ...  Combined_Key_Zamboanga del Sur ,Philippines  \\\n",
       "0                10.390897  ...                                            0   \n",
       "1               209.514800  ...                                            0   \n",
       "2               204.687238  ...                                            0   \n",
       "3               126.061115  ...                                            0   \n",
       "4               217.585376  ...                                            0   \n",
       "...                    ...  ...                                          ...   \n",
       "367629           -1.000000  ...                                            0   \n",
       "367630           10.390897  ...                                            0   \n",
       "367631          111.254821  ...                                            0   \n",
       "367632            0.367129  ...                                            0   \n",
       "367633           47.256340  ...                                            0   \n",
       "\n",
       "        Combined_Key_Zamfara ,Nigeria  Combined_Key_Zanjan ,Iran  \\\n",
       "0                                   0                          0   \n",
       "1                                   0                          0   \n",
       "2                                   0                          0   \n",
       "3                                   0                          0   \n",
       "4                                   0                          0   \n",
       "...                               ...                        ...   \n",
       "367629                              0                          0   \n",
       "367630                              0                          0   \n",
       "367631                              0                          0   \n",
       "367632                              0                          0   \n",
       "367633                              0                          0   \n",
       "\n",
       "        Combined_Key_Zeeland, Netherlands  Combined_Key_Zhejiang, China  \\\n",
       "0                                       0                             0   \n",
       "1                                       0                             0   \n",
       "2                                       0                             0   \n",
       "3                                       0                             0   \n",
       "4                                       0                             0   \n",
       "...                                   ...                           ...   \n",
       "367629                                  0                             0   \n",
       "367630                                  0                             0   \n",
       "367631                                  0                             0   \n",
       "367632                                  0                             0   \n",
       "367633                                  0                             0   \n",
       "\n",
       "        Combined_Key_Zimbabwe  Combined_Key_Zuid-Holland, Netherlands  \\\n",
       "0                           0                                       0   \n",
       "1                           0                                       0   \n",
       "2                           0                                       0   \n",
       "3                           0                                       0   \n",
       "4                           0                                       0   \n",
       "...                       ...                                     ...   \n",
       "367629                      0                                       0   \n",
       "367630                      0                                       0   \n",
       "367631                      0                                       0   \n",
       "367632                      0                                       0   \n",
       "367633                      0                                       0   \n",
       "\n",
       "        Combined_Key_galapagos ,Ecuador  Combined_Key_Ñeembucu ,Paraguay  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "...                                 ...                              ...   \n",
       "367629                                0                                0   \n",
       "367630                                0                                0   \n",
       "367631                                0                                0   \n",
       "367632                                0                                0   \n",
       "367633                                0                                0   \n",
       "\n",
       "        Combined_Key_ñeembucu ,Paraguay  \n",
       "0                                     0  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  \n",
       "...                                 ...  \n",
       "367629                                0  \n",
       "367630                                0  \n",
       "367631                                0  \n",
       "367632                                0  \n",
       "367633                                0  \n",
       "\n",
       "[367634 rows x 2789 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>date_confirmation</th>\n      <th>outcome</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Active</th>\n      <th>Incidence_Rate</th>\n      <th>Case-Fatality_Ratio</th>\n      <th>dist_between_in_km</th>\n      <th>...</th>\n      <th>Combined_Key_Zamboanga del Sur ,Philippines</th>\n      <th>Combined_Key_Zamfara ,Nigeria</th>\n      <th>Combined_Key_Zanjan ,Iran</th>\n      <th>Combined_Key_Zeeland, Netherlands</th>\n      <th>Combined_Key_Zhejiang, China</th>\n      <th>Combined_Key_Zimbabwe</th>\n      <th>Combined_Key_Zuid-Holland, Netherlands</th>\n      <th>Combined_Key_galapagos ,Ecuador</th>\n      <th>Combined_Key_Ñeembucu ,Paraguay</th>\n      <th>Combined_Key_ñeembucu ,Paraguay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2020-05-26</td>\n      <td>recovered</td>\n      <td>238828.000000</td>\n      <td>4907.000000</td>\n      <td>201671.000000</td>\n      <td>32250.000000</td>\n      <td>1276.409575</td>\n      <td>2.054617</td>\n      <td>10.390897</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>2020-05-20</td>\n      <td>hospitalized</td>\n      <td>342788.000000</td>\n      <td>4869.000000</td>\n      <td>270094.000000</td>\n      <td>67825.000000</td>\n      <td>144.099577</td>\n      <td>1.420411</td>\n      <td>209.514800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>2020-05-26</td>\n      <td>hospitalized</td>\n      <td>2859.000000</td>\n      <td>2.000000</td>\n      <td>2639.000000</td>\n      <td>218.000000</td>\n      <td>464.331421</td>\n      <td>0.069955</td>\n      <td>204.687238</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-03-15</td>\n      <td>nonhospitalized</td>\n      <td>46779.000000</td>\n      <td>1871.000000</td>\n      <td>41228.000000</td>\n      <td>3680.000000</td>\n      <td>422.592353</td>\n      <td>3.999658</td>\n      <td>126.061115</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>2020-05-20</td>\n      <td>hospitalized</td>\n      <td>120336.000000</td>\n      <td>3286.000000</td>\n      <td>100974.000000</td>\n      <td>16076.000000</td>\n      <td>188.400627</td>\n      <td>2.730687</td>\n      <td>217.585376</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>367629</th>\n      <td>3</td>\n      <td>2020-03-31</td>\n      <td>nonhospitalized</td>\n      <td>106331.902334</td>\n      <td>2739.064287</td>\n      <td>77838.956438</td>\n      <td>25753.923921</td>\n      <td>968.698456</td>\n      <td>2.721038</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367630</th>\n      <td>7</td>\n      <td>2020-04-16</td>\n      <td>hospitalized</td>\n      <td>238828.000000</td>\n      <td>4907.000000</td>\n      <td>201671.000000</td>\n      <td>32250.000000</td>\n      <td>1276.409575</td>\n      <td>2.054617</td>\n      <td>10.390897</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367631</th>\n      <td>7</td>\n      <td>2020-05-30</td>\n      <td>hospitalized</td>\n      <td>2859.000000</td>\n      <td>2.000000</td>\n      <td>2639.000000</td>\n      <td>218.000000</td>\n      <td>464.331421</td>\n      <td>0.069955</td>\n      <td>111.254821</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367632</th>\n      <td>3</td>\n      <td>2020-03-02</td>\n      <td>recovered</td>\n      <td>57558.000000</td>\n      <td>27.000000</td>\n      <td>57142.000000</td>\n      <td>389.000000</td>\n      <td>983.839751</td>\n      <td>0.046909</td>\n      <td>0.367129</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367633</th>\n      <td>1</td>\n      <td>2020-05-27</td>\n      <td>nonhospitalized</td>\n      <td>33299.000000</td>\n      <td>1911.000000</td>\n      <td>0.000000</td>\n      <td>31388.000000</td>\n      <td>1625.927734</td>\n      <td>5.738911</td>\n      <td>47.256340</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>367634 rows × 2789 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "# add dummy variables  \n",
    "ohe_df = oneHotEncode_df(df)\n",
    "ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7, Timestamp('2020-05-26 00:00:00'), 'recovered', ..., 0, 0, 0],\n",
       "       [7, Timestamp('2020-05-20 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       [7, Timestamp('2020-05-26 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       ...,\n",
       "       [7, Timestamp('2020-05-30 00:00:00'), 'hospitalized', ..., 0, 0,\n",
       "        0],\n",
       "       [3, Timestamp('2020-03-02 00:00:00'), 'recovered', ..., 0, 0, 0],\n",
       "       [1, Timestamp('2020-05-27 00:00:00'), 'nonhospitalized', ..., 0,\n",
       "        0, 0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "ohe_np = ohe_df.to_numpy()\n",
    "ohe_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into dependent and independent var\n",
    "x = ohe_df.copy().drop(columns=['outcome','date_confirmation','dist_between_in_km'])\n",
    "y = ohe_df.outcome.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 35 s, sys: 0 ns, total: 35 s\nWall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split train data\n",
    "trainData_x, validationData_x, trainData_y, validationData_y = train_test_split(x,y, train_size=0.8, random_state=1)"
   ]
  },
  {
   "source": [
    "# ----------------------------------Model Building-----------------------------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 diff classififers and append them to list\n",
    "classifiers = []\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "classifiers.append(xgb_model)\n",
    "\n",
    "nn_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "classifiers.append(nn_model)\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "classifiers.append(svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get small sample sice\n",
    "sub_x = trainData_x.iloc[0:50000]\n",
    "sub_y = trainData_y.iloc[0:50000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "CPU times: user 32.1 s, sys: 4.55 s, total: 36.6 s\n",
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "#test neural net\n",
    "nn_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "nn_model.fit(sub_x,sub_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = validationData_x.iloc[0:50000]\n",
    "val_y = validationData_y.iloc[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "CPU times: user 1.27 s, sys: 280 ms, total: 1.55 s\n",
      "Wall time: 1.03 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.40812"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "%%time\n",
    "ans = nn_model.score(val_x,val_y)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing with small data set\n",
    "t_x, v_x, t_y, v_y = train_test_split(x.iloc[0:1000],y.iloc[0:1000], train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test models with full samples\n",
    "# for clas in tqdm(classifiers):\n",
    "#     clas.fit(trainData_x,trainData_y)\n",
    "#     predicted = clas.predict(validationData_x)\n",
    "#     accuracy = accuracy_score(validationData_y,predicted)\n",
    "#     print(\"Accuracy of %s is %s\"%(clas, accuracy))\n",
    "#     con_mat = confusion_matrix(validationData_y,predicted)\n",
    "#     print(\"Confusion Matrix of %s is %s\"%(clas, con_mat))\n",
    "#     pickle.dump( clas, open( \"{}{}.pkl\".format(clas,i), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "218247    2\n",
       "33854     0\n",
       "234440    3\n",
       "316468    3\n",
       "250495    2\n",
       "         ..\n",
       "117583    3\n",
       "73349     2\n",
       "312201    3\n",
       "267336    3\n",
       "128037    0\n",
       "Name: outcome, Length: 294107, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_trainInt = pd.Series(trainData_y).replace({'recovered' : 0, 'deceased' : 1, 'nonhospitalized' : 2, 'hospitalized' : 3})\n",
    "y_trainInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "247886    2\n",
       "364290    2\n",
       "237307    3\n",
       "22967     3\n",
       "29696     3\n",
       "         ..\n",
       "47882     3\n",
       "319748    2\n",
       "153914    2\n",
       "219937    2\n",
       "352073    2\n",
       "Name: outcome, Length: 73527, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_validInt = pd.Series(validationData_y).replace({'recovered' : 0, 'deceased' : 1, 'nonhospitalized' : 2, 'hospitalized' : 3})\n",
    "y_validInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 14.9 s, sys: 2.77 s, total: 17.7 s\nWall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert into Dmatrix\n",
    "data_matrix = xgb.DMatrix(data=trainData_x,label=y_trainInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2.81 s, sys: 517 ms, total: 3.33 s\nWall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert into Dmatrix\n",
    "valid_matrix = xgb.DMatrix(data=validationData_x,label=y_validInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "xgboost.core.DMatrix"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "type(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = xgb.DMatrix(data=trainData_x.iloc[0:1000],label=y_trainInt.iloc[0:1000])\n",
    "vm = xgb.DMatrix(data=validationData_x.iloc[0:1000],label=y_validInt.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[00:09:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train score is 0.809\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 1/5 [00:04<00:19,  4.81s/it]val score is 0.767\n",
      "Accuracy of XGBClassifier is 0.0\n",
      "Confusion Matrix of xgbmodel is [[  0   9   1   2]\n",
      " [  0 318   1  20]\n",
      " [  0   0 411   0]\n",
      " [  0 185  15  38]]\n",
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[00:09:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=5, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train score is 0.809\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 2/5 [00:10<00:16,  5.45s/it]val score is 0.767\n",
      "Accuracy of XGBClassifier is 0.0\n",
      "Confusion Matrix of xgbmodel is [[  0   9   1   2]\n",
      " [  0 318   1  20]\n",
      " [  0   0 411   0]\n",
      " [  0 185  15  38]]\n",
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[00:09:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train score is 0.816\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 3/5 [00:18<00:12,  6.38s/it]val score is 0.771\n",
      "Accuracy of XGBClassifier is 0.0\n",
      "Confusion Matrix of xgbmodel is [[  0   9   1   2]\n",
      " [  0 317   1  21]\n",
      " [  0   0 409   2]\n",
      " [  0 178  15  45]]\n",
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[00:09:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=25, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train score is 0.828\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 4/5 [00:32<00:09,  9.41s/it]val score is 0.773\n",
      "Accuracy of XGBClassifier is 0.0\n",
      "Confusion Matrix of xgbmodel is [[  0   9   1   2]\n",
      " [  0 308   1  30]\n",
      " [  0   0 409   2]\n",
      " [  0 167  15  56]]\n",
      "/home/olay/Cmpt459/DoR459_Proj/venv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[00:10:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train score is 0.835\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5/5 [00:52<00:00, 10.57s/it]val score is 0.77\n",
      "Accuracy of XGBClassifier is 0.0\n",
      "Confusion Matrix of xgbmodel is [[  0   9   1   2]\n",
      " [  0 300   1  38]\n",
      " [  0   0 409   2]\n",
      " [  0 163  14  61]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = [1,5,10,25,50]\n",
    "\n",
    "for i in tqdm(n):\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=i)\n",
    "    xfit = xgb_model.fit(trainData_x,trainData_y)\n",
    "    predicted = xgb_model.predict(validationData_x)\n",
    "\n",
    "    tscore = xgb_model.score(trainData_x,y_trainInt)\n",
    "    print(\"train score is {}\".format(tscore))\n",
    "    vscore = xgb_model.score(validationData_x,y_validInt)\n",
    "    print(\"val score is {}\".format(vscore))\n",
    "    accuracy = accuracy_score(y_validInt,predicted)\n",
    "    print(\"Accuracy of XGBClassifier is {}\".format(accuracy))\n",
    "    con_mat = confusion_matrix(validationData_y,predicted)\n",
    "    print(\"Confusion Matrix of xgbmodel is {}\".format(con_mat))\n",
    "    pickle.dump( xgb_model, open( \"xgboost{}.pkl\".format(i), \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump( clf, open( \"AdaBoost50.pkl\", \"wb\" ) )"
   ]
  },
  {
   "source": [
    "# Exploratory Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}